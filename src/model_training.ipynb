{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# General imports.\nfrom tqdm.notebook import tqdm\n\n# Specific imports.\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.optim import AdamW, SGD\nfrom torch.utils.data import DataLoader\nfrom transformers import get_scheduler, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import BertTokenizerFast, BertForSequenceClassification\nfrom torch.profiler import profile, record_function, ProfilerActivity\nfrom torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:14:42.339862Z","iopub.execute_input":"2023-06-03T00:14:42.341879Z","iopub.status.idle":"2023-06-03T00:15:08.457776Z","shell.execute_reply.started":"2023-06-03T00:14:42.341775Z","shell.execute_reply":"2023-06-03T00:15:08.456108Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/mbti-tweets/cleaned_df.csv\")\ndata = data.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:33.140176Z","iopub.execute_input":"2023-06-03T00:15:33.140885Z","iopub.status.idle":"2023-06-03T00:15:36.638601Z","shell.execute_reply.started":"2023-06-03T00:15:33.140828Z","shell.execute_reply":"2023-06-03T00:15:36.636573Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"labels = ['intj', 'intp', 'entj', 'entp', 'infj', 'infp', 'enfj', 'enfp', 'istj', 'isfj', 'estj', 'esfj', 'istp', 'isfp', 'estp', 'esfp']\nid2label = {id:label for id,label in enumerate(labels)}\nlabel2id = {label:id for id,label in enumerate(labels)}","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:39.070479Z","iopub.execute_input":"2023-06-03T00:15:39.072366Z","iopub.status.idle":"2023-06-03T00:15:39.099136Z","shell.execute_reply.started":"2023-06-03T00:15:39.072294Z","shell.execute_reply":"2023-06-03T00:15:39.096908Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CustomTextDataset(torch.utils.data.Dataset):\n    def __init__(self, data, model_name=\"bert-base-uncased\"):\n        self.data = data\n        self.tokenizer = BertTokenizerFast.from_pretrained(model_name)\n        self.label = data['label'].apply(lambda l: label2id[l])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        res = self.tokenizer(text=self.data.iloc[idx].get('cleaned_text'), \n                             padding='max_length', \n                             max_length=500, \n                             truncation=True, \n                             return_tensors='pt')\n        #F.one_hot(torch.tensor(self.label[idx]), num_classes=16).to(torch.float)\n        return {\n            'input_ids': res[\"input_ids\"].squeeze(), \n            'token_type_ids': res[\"token_type_ids\"].squeeze(), \n            'attention_mask': res[\"attention_mask\"].squeeze(),\n            \"labels\": torch.tensor(self.label[idx])\n        }","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:40.649085Z","iopub.execute_input":"2023-06-03T00:15:40.649641Z","iopub.status.idle":"2023-06-03T00:15:40.663059Z","shell.execute_reply.started":"2023-06-03T00:15:40.649597Z","shell.execute_reply":"2023-06-03T00:15:40.661627Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ds = CustomTextDataset(data)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:42.951344Z","iopub.execute_input":"2023-06-03T00:15:42.952067Z","iopub.status.idle":"2023-06-03T00:15:44.736252Z","shell.execute_reply.started":"2023-06-03T00:15:42.952020Z","shell.execute_reply":"2023-06-03T00:15:44.735075Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1468003a86eb4420b6dba05db556e0f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec37c716175d47eb863203647c078656"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4504bf4e14d54af0a524cf3e5e8fba06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a207afdd8b884a25879b83d19db2c0dc"}},"metadata":{}}]},{"cell_type":"code","source":"BATCH_SIZE = 20\n\ntrain_indices, test_indices = train_test_split(\n    range(len(ds)),\n    test_size=0.1,\n)\ntrain_split = Subset(ds, train_indices)\ntest_split = Subset(ds, test_indices)\n\ntrain_batches = DataLoader(\n    train_split, \n    batch_size=BATCH_SIZE, \n    shuffle=True,\n    num_workers = 0,\n    pin_memory = True,\n    drop_last = True\n)\ntest_batches = DataLoader(test_split, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:46.786122Z","iopub.execute_input":"2023-06-03T00:15:46.786573Z","iopub.status.idle":"2023-06-03T00:15:46.797330Z","shell.execute_reply.started":"2023-06-03T00:15:46.786536Z","shell.execute_reply":"2023-06-03T00:15:46.795509Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# ds = CustomTextDataset(data)\n# train_loader = DataLoader(\n#     ds, \n#     batch_size = 20, \n#     shuffle = True, \n#     num_workers = 0, \n#     pin_memory = True, \n#     drop_last = True,\n# )","metadata":{"execution":{"iopub.status.busy":"2023-05-23T01:56:46.144191Z","iopub.execute_input":"2023-05-23T01:56:46.144532Z","iopub.status.idle":"2023-05-23T01:56:46.148527Z","shell.execute_reply.started":"2023-05-23T01:56:46.144505Z","shell.execute_reply":"2023-05-23T01:56:46.147567Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class ClassifierHead(nn.Module):\n    def __init__(self, hidden_size, num_classes, seq_length):\n        super().__init__()\n        self.rnn = nn.RNN(768, hidden_size, batch_first=True)\n        self.linear = nn.Linear(hidden_size*seq_length, num_classes)\n\n    def forward(self, x):\n        x, _ = self.rnn(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.linear(x)\n        return x\n\nclass BERTWithClassifierHead(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n        # ClassifierHead is already defined.\n        self.classifier = ClassifierHead(20, num_classes, 500)\n        \n    def forward(self, x):\n        x = self.bert(**x)\n        x = x.last_hidden_state\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:50.912862Z","iopub.execute_input":"2023-06-03T00:15:50.913378Z","iopub.status.idle":"2023-06-03T00:15:50.923628Z","shell.execute_reply.started":"2023-06-03T00:15:50.913337Z","shell.execute_reply":"2023-06-03T00:15:50.922402Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = BERTWithClassifierHead(num_classes=16)\n# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 16, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:15:53.459311Z","iopub.execute_input":"2023-06-03T00:15:53.460014Z","iopub.status.idle":"2023-06-03T00:15:56.861602Z","shell.execute_reply.started":"2023-06-03T00:15:53.459981Z","shell.execute_reply":"2023-06-03T00:15:56.860637Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76da1e4362bd4f769883336d46688703"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n# model.to(device)\n# batch = next(iter(train_batches))\n# X = {k: batch[k] for k in batch.keys() if k not in [\"label\"]}\n# y = batch[\"label\"]\n# X = {k: v.to(device) for k, v in X.items()}\n# y = y.to(device)\n# output = model(**X).logits\n# print(output.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T04:39:31.649887Z","iopub.execute_input":"2023-05-19T04:39:31.650275Z","iopub.status.idle":"2023-05-19T04:39:39.206206Z","shell.execute_reply.started":"2023-05-19T04:39:31.650236Z","shell.execute_reply":"2023-05-19T04:39:39.205109Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.Size([25, 16]) torch.Size([25, 16])\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 3\nlr = 5e-5\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n# Define Loss\ncriterion = nn.CrossEntropyLoss()\n\n# Define optimizer.\noptimizer = AdamW(model.parameters(), lr=lr)\n# optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n\n# Define LR Scheduler.\nnum_training_steps = epochs * len(train_batches)\nlr_scheduler = get_scheduler(\n    name=\"cosine\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-27T23:18:57.720973Z","iopub.execute_input":"2023-05-27T23:18:57.721446Z","iopub.status.idle":"2023-05-27T23:19:03.742185Z","shell.execute_reply.started":"2023-05-27T23:18:57.721408Z","shell.execute_reply":"2023-05-27T23:19:03.741241Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BERTWithClassifierHead(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classifier): ClassifierHead(\n    (rnn): RNN(768, 20, batch_first=True)\n    (linear): Linear(in_features=10000, out_features=16, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# model.to(device)\n# with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n#     with record_function(\"model_inference\"):\n#         batch = next(iter(train_loader))\n#         X = {k: batch[k] for k in batch.keys() if k not in [\"label\"]}\n#         y = batch[\"label\"]\n#         X = {k: v.to(device) for k, v in X.items()}\n#         y = y.to(device)\n#         model(X)\n# print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:19:14.559814Z","iopub.execute_input":"2023-05-19T07:19:14.560212Z","iopub.status.idle":"2023-05-19T07:19:14.564758Z","shell.execute_reply.started":"2023-05-19T07:19:14.560180Z","shell.execute_reply":"2023-05-19T07:19:14.563872Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler()\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(epochs):\n    \n    running_loss = 0.0\n    for i, batch in enumerate(train_batches, 0):\n        \n        batch = {k: v.to(device) for k, v in batch.items()}\n        # Unpack the dictionary.\n        X = {k: batch[k] for k in batch.keys() if k not in \"labels\"}\n        y = batch[\"labels\"]\n\n#         One step.\n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(X)\n            loss = criterion(outputs, y)\n            \n#         loss.backward()\n#         optimizer.step()\n\n        scaler.scale(loss).backward()\n\n        scaler.step(optimizer)\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        \n        scaler.update()\n        \n        progress_bar.update(1)\n    \n        running_loss += loss.item()\n        if i % 50 == 49:    # print every 45 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n            running_loss = 0.0\n            \nprint(\"Finished Training!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-27T23:19:25.589989Z","iopub.execute_input":"2023-05-27T23:19:25.590327Z","iopub.status.idle":"2023-05-27T23:38:20.560295Z","shell.execute_reply.started":"2023-05-27T23:19:25.590298Z","shell.execute_reply":"2023-05-27T23:38:20.559378Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/978 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b662f52c199c40e0ad4a9e7950da7e09"}},"metadata":{}},{"name":"stdout","text":"[1,    50] loss: 2.636\n[1,   100] loss: 2.600\n[1,   150] loss: 2.633\n[1,   200] loss: 2.577\n[1,   250] loss: 2.623\n[1,   300] loss: 2.608\n[2,    50] loss: 2.573\n[2,   100] loss: 2.574\n[2,   150] loss: 2.554\n[2,   200] loss: 2.586\n[2,   250] loss: 2.545\n[2,   300] loss: 2.569\n[3,    50] loss: 2.555\n[3,   100] loss: 2.566\n[3,   150] loss: 2.486\n[3,   200] loss: 2.542\n[3,   250] loss: 2.516\n[3,   300] loss: 2.523\nFinished Training!\n","output_type":"stream"}]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler()\n\nbatch = next(iter(train_batches))\n    \nbatch = {k: v.to(device) for k, v in batch.items()}\n# Unpack the dictionary.\nX = {k: batch[k] for k in batch.keys() if k not in \"labels\"}\ny = batch[\"labels\"]\nfor epoch in range(100):\n\n#         One step.\n    with torch.autocast(device_type='cuda', dtype=torch.float16):\n        outputs = model(X)\n        loss = criterion(outputs, y)\n            \n#         loss.backward()\n#         optimizer.step()\n\n    scaler.scale(loss).backward()\n\n    scaler.step(optimizer)\n    lr_scheduler.step()\n    optimizer.zero_grad()\n\n    scaler.update()\n\n    progress_bar.update(1)\n\n    print(f'{epoch}=', loss)\n            \nprint(\"Finished Training!\")","metadata":{"execution":{"iopub.status.busy":"2023-05-23T02:07:33.023539Z","iopub.execute_input":"2023-05-23T02:07:33.023920Z","iopub.status.idle":"2023-05-23T02:09:17.427928Z","shell.execute_reply.started":"2023-05-23T02:07:33.023891Z","shell.execute_reply":"2023-05-23T02:09:17.426886Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"0= tensor(4.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n1= tensor(3.9684, device='cuda:0', grad_fn=<NllLossBackward0>)\n2= tensor(3.6470, device='cuda:0', grad_fn=<NllLossBackward0>)\n3= tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n4= tensor(2.9921, device='cuda:0', grad_fn=<NllLossBackward0>)\n5= tensor(2.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n6= tensor(2.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n7= tensor(2.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n8= tensor(2.5209, device='cuda:0', grad_fn=<NllLossBackward0>)\n9= tensor(2.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n10= tensor(2.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n11= tensor(2.5352, device='cuda:0', grad_fn=<NllLossBackward0>)\n12= tensor(2.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n13= tensor(2.4558, device='cuda:0', grad_fn=<NllLossBackward0>)\n14= tensor(2.3696, device='cuda:0', grad_fn=<NllLossBackward0>)\n15= tensor(2.3812, device='cuda:0', grad_fn=<NllLossBackward0>)\n16= tensor(2.3550, device='cuda:0', grad_fn=<NllLossBackward0>)\n17= tensor(2.3861, device='cuda:0', grad_fn=<NllLossBackward0>)\n18= tensor(2.3781, device='cuda:0', grad_fn=<NllLossBackward0>)\n19= tensor(2.3827, device='cuda:0', grad_fn=<NllLossBackward0>)\n20= tensor(2.4145, device='cuda:0', grad_fn=<NllLossBackward0>)\n21= tensor(2.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n22= tensor(2.3919, device='cuda:0', grad_fn=<NllLossBackward0>)\n23= tensor(2.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n24= tensor(2.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n25= tensor(2.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n26= tensor(2.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n27= tensor(2.3599, device='cuda:0', grad_fn=<NllLossBackward0>)\n28= tensor(2.3314, device='cuda:0', grad_fn=<NllLossBackward0>)\n29= tensor(2.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n30= tensor(2.3769, device='cuda:0', grad_fn=<NllLossBackward0>)\n31= tensor(2.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n32= tensor(2.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n33= tensor(2.2967, device='cuda:0', grad_fn=<NllLossBackward0>)\n34= tensor(2.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n35= tensor(2.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n36= tensor(2.3547, device='cuda:0', grad_fn=<NllLossBackward0>)\n37= tensor(2.3331, device='cuda:0', grad_fn=<NllLossBackward0>)\n38= tensor(2.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n39= tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n40= tensor(2.3132, device='cuda:0', grad_fn=<NllLossBackward0>)\n41= tensor(2.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n42= tensor(2.3421, device='cuda:0', grad_fn=<NllLossBackward0>)\n43= tensor(2.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n44= tensor(2.3814, device='cuda:0', grad_fn=<NllLossBackward0>)\n45= tensor(2.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n46= tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n47= tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n48= tensor(2.3681, device='cuda:0', grad_fn=<NllLossBackward0>)\n49= tensor(2.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n50= tensor(2.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n51= tensor(2.3477, device='cuda:0', grad_fn=<NllLossBackward0>)\n52= tensor(2.2834, device='cuda:0', grad_fn=<NllLossBackward0>)\n53= tensor(2.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n54= tensor(2.2946, device='cuda:0', grad_fn=<NllLossBackward0>)\n55= tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward0>)\n56= tensor(2.3356, device='cuda:0', grad_fn=<NllLossBackward0>)\n57= tensor(2.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n58= tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n59= tensor(2.3140, device='cuda:0', grad_fn=<NllLossBackward0>)\n60= tensor(2.3807, device='cuda:0', grad_fn=<NllLossBackward0>)\n61= tensor(2.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n62= tensor(2.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n63= tensor(2.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n64= tensor(2.3488, device='cuda:0', grad_fn=<NllLossBackward0>)\n65= tensor(2.3224, device='cuda:0', grad_fn=<NllLossBackward0>)\n66= tensor(2.3637, device='cuda:0', grad_fn=<NllLossBackward0>)\n67= tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n68= tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward0>)\n69= tensor(2.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n70= tensor(2.3021, device='cuda:0', grad_fn=<NllLossBackward0>)\n71= tensor(2.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n72= tensor(2.3908, device='cuda:0', grad_fn=<NllLossBackward0>)\n73= tensor(2.4052, device='cuda:0', grad_fn=<NllLossBackward0>)\n74= tensor(2.2917, device='cuda:0', grad_fn=<NllLossBackward0>)\n75= tensor(2.3854, device='cuda:0', grad_fn=<NllLossBackward0>)\n76= tensor(2.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n77= tensor(2.3159, device='cuda:0', grad_fn=<NllLossBackward0>)\n78= tensor(2.3135, device='cuda:0', grad_fn=<NllLossBackward0>)\n79= tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n80= tensor(2.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n81= tensor(2.3392, device='cuda:0', grad_fn=<NllLossBackward0>)\n82= tensor(2.3315, device='cuda:0', grad_fn=<NllLossBackward0>)\n83= tensor(2.3385, device='cuda:0', grad_fn=<NllLossBackward0>)\n84= tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n85= tensor(2.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n86= tensor(2.3222, device='cuda:0', grad_fn=<NllLossBackward0>)\n87= tensor(2.3237, device='cuda:0', grad_fn=<NllLossBackward0>)\n88= tensor(2.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n89= tensor(2.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n90= tensor(2.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n91= tensor(2.3564, device='cuda:0', grad_fn=<NllLossBackward0>)\n92= tensor(2.2652, device='cuda:0', grad_fn=<NllLossBackward0>)\n93= tensor(2.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n94= tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n95= tensor(2.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n96= tensor(2.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n97= tensor(2.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n98= tensor(2.3148, device='cuda:0', grad_fn=<NllLossBackward0>)\n99= tensor(2.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\nFinished Training!\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/mbti.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-28T00:11:17.805552Z","iopub.execute_input":"2023-05-28T00:11:17.805913Z","iopub.status.idle":"2023-05-28T00:11:18.936764Z","shell.execute_reply.started":"2023-05-28T00:11:17.805885Z","shell.execute_reply":"2023-05-28T00:11:18.935413Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = BERTWithClassifierHead(num_classes=16)\n# model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=16)\nmodel.load_state_dict(torch.load('/kaggle/working/mbti.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:16:14.904430Z","iopub.execute_input":"2023-06-03T00:16:14.904774Z","iopub.status.idle":"2023-06-03T00:16:21.480476Z","shell.execute_reply.started":"2023-06-03T00:16:14.904747Z","shell.execute_reply":"2023-06-03T00:16:21.479434Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\nres = tokenizer(text=\"this is some text hello hello hello\", \n                             padding='max_length', \n                             max_length=500, \n                             truncation=True, \n                             return_tensors='pt')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:35:08.402554Z","iopub.execute_input":"2023-06-03T00:35:08.403165Z","iopub.status.idle":"2023-06-03T00:35:08.586918Z","shell.execute_reply.started":"2023-06-03T00:35:08.403131Z","shell.execute_reply":"2023-06-03T00:35:08.585926Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"output = model(res)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:41:07.088872Z","iopub.execute_input":"2023-06-03T00:41:07.089231Z","iopub.status.idle":"2023-06-03T00:41:08.114778Z","shell.execute_reply.started":"2023-06-03T00:41:07.089202Z","shell.execute_reply":"2023-06-03T00:41:08.113631Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"tensor([[ 0.8819,  1.4050,  0.1773,  0.3725,  1.2178,  1.7634,  0.0153,  0.8813,\n         -0.2533, -0.4657, -1.7859, -1.7720, -0.3982,  0.2173, -1.5934, -0.8718]],\n       grad_fn=<AddmmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"m = nn.Softmax(dim=1)\nscaled = m(output)\nprint(scaled)\nprediction = torch.argmax(scaled)\nprediction","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:42:08.167289Z","iopub.execute_input":"2023-06-03T00:42:08.167718Z","iopub.status.idle":"2023-06-03T00:42:08.181637Z","shell.execute_reply.started":"2023-06-03T00:42:08.167688Z","shell.execute_reply":"2023-06-03T00:42:08.180429Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"tensor([[0.0927, 0.1564, 0.0458, 0.0557, 0.1297, 0.2238, 0.0390, 0.0927, 0.0298,\n         0.0241, 0.0064, 0.0065, 0.0258, 0.0477, 0.0078, 0.0161]],\n       grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensor(5)"},"metadata":{}}]},{"cell_type":"code","source":"type(labels[prediction])","metadata":{"execution":{"iopub.status.busy":"2023-06-03T00:47:05.421266Z","iopub.execute_input":"2023-06-03T00:47:05.421704Z","iopub.status.idle":"2023-06-03T00:47:05.428465Z","shell.execute_reply.started":"2023-06-03T00:47:05.421673Z","shell.execute_reply":"2023-06-03T00:47:05.427440Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}]},{"cell_type":"code","source":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    for batch in test_batches:\n        X = {k: batch[k] for k in batch.keys() if k not in \"label\"}\n        y = batch[\"label\"]\n\n        X = {k: v.to(device) for k, v in X.items()}\n        y = y.to(device)\n\n        outputs = model(**X).logits\n        _, predicted = torch.max(outputs, 1)\n        _, actual = torch.max(y, 1)\n\n        total += actual.size(0)\n        correct += (predicted == actual).sum().item()\n    \nprint(f'Accuracy of the model: {100 * correct // total} %')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T04:59:11.722432Z","iopub.execute_input":"2023-05-19T04:59:11.722795Z","iopub.status.idle":"2023-05-19T04:59:42.741499Z","shell.execute_reply.started":"2023-05-19T04:59:11.722766Z","shell.execute_reply":"2023-05-19T04:59:42.740571Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy of the model: 16 %\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"accuracy\")\nmodel.eval()\nfor batch in test_batches:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    actual = torch.argmax(batch['labels'], dim=-1)\n    metric.add_batch(predictions=predictions, references=actual)\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T05:33:02.749744Z","iopub.execute_input":"2023-05-19T05:33:02.750103Z","iopub.status.idle":"2023-05-19T05:33:33.686290Z","shell.execute_reply.started":"2023-05-19T05:33:02.750077Z","shell.execute_reply":"2023-05-19T05:33:33.685427Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.21335168616655195}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-19T05:31:30.332590Z","iopub.execute_input":"2023-05-19T05:31:30.332965Z","iopub.status.idle":"2023-05-19T05:31:30.341106Z","shell.execute_reply.started":"2023-05-19T05:31:30.332937Z","shell.execute_reply":"2023-05-19T05:31:30.340065Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"tensor([ 1,  0,  3,  8,  7, 14,  5,  1,  4,  1,  4,  4,  5,  6,  0,  5,  0,  7,\n         1,  6,  7, 10,  0, 14,  1], device='cuda:0')\n","output_type":"stream"}]}]}
